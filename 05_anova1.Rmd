---
title: "Однофакторный дисперсионный анализ"
subtitle: ""
author: 
  - Марина Варфоломеева
  - Анастасия Лянгузова
  - Вадим Хайтов
output:
  xaringan::moon_reader:
    self-contained: true
    lib_dir: libs
    css: [default, tamu-fonts, ninjutsu, "assets/xaringan-themer.css", "assets/xaringan.css"]
    df_print: default
    nature:
      highlightStyle: vs
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: [middle, left, inverse]
      beforeInit: "assets/macros.js"
    includes:
      in_header: "assets/xaringan_in_header.html"
      after_body: "assets/xaringan_after_body.html"
---


```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
source("assets/xaringan_setup.R")
library(xaringanExtra)
use_tile_view()
use_scribble()
use_search(show_icon = FALSE)
use_progress_bar(color = "#98BF64", location = "bottom", height = "10px")
use_freezeframe()
# use_webcam()
# use_panelset()
# use_extra_styles(hover_code_line = TRUE)

# http://tachyons.io/docs/
# https://roperzh.github.io/tachyons-cheatsheet/
use_tachyons()
# source('support_mathmethr.R')
```

```{r libs, echo=FALSE}
library(ggplot2)
theme_set(theme_bw())
library(grid)
library(gridExtra) # to rescale legend
```

## Знакомимся c дисперсионным анализом

### Вы сможете

- Объяснить, в чем опасность множественных сравнений, и как с ними можно бороться
- Рассказать, из каких частей состоит общая изменчивость
- Перечислить и проверить условия применимости дисперсионного анализа

---

class: middle, center, inverse

## Разведочный анализ данныx

---

## Пример: сон у млекопитающих

Известно, что у разных млекопитающих продолжительность сна сильно варьирует. Ленивцы спят , коалы спят, а  кому-то достаточно. Условия жизни у всех тоже разные. Давайте проверим, есть ли связь между продолжительностью сна и уровнем опасности среды.

- `TotalSleep` - общая продолжительность сна. В нашем анализе это будет зависимая переменная
- `Danger`  - уровень опасности среды для вида, пять градаций (1 - 5)

.tiny[ 
Данные: Allison, Cicchetti (1976), электронная версия [Statlib database](http://lib.stat.cmu.edu)
]

---

## Читаем данные из файла одним из способов

### Чтение из csv

```{r}
sleep <- read.table('data/sleep.csv', header = TRUE, sep = '\t')
```

---

## Все ли правильно открылось?

```{r}
str(sleep) # Структура данных
head(sleep, 2)     # Первые несколько строк файла
```


```{r}
# Сделаем sleep$Danger фактором
sleep$Danger <- factor(sleep$Danger, levels = 1:5, labels = c('очень низкий', 'низкий', 'средний', 'высокий', 'очень высокий'))
```

---

## Знакомимся с данными

Есть ли пропущенные значения (особенно, в переменных, которые нас интересуют)?

```{r}
colSums(is.na(sleep))
```

К счастью, про уровень опасности (`Danger`) информация есть для всех объектов.

Но есть пропущенные значения продолжительности сна (`TotalSleep`). 

---

## Каков объем выборки?

В одной из переменных, которые нам интересны, есть пропущенные значения. Это нужно учесть при рассчете объема выборки.

Удалим из датафрейма `sleep` строки, где `TotalSleep` принимает значение `NA`.

```{r}
sl <- sleep[!is.na(sleep$TotalSleep), ]
```


Дальше будем работать с датафреймом `sl`. В нем нет пропущенных значений в интересующих нас переменных.

```{r}
nrow(sl)
```

Каков объем выборки в каждой группе?

```{r}
table(sl$Danger)
```

---

## Визуализация материала 

```{r gg-points, echo=FALSE, purl=FALSE}
library(ggplot2)
theme_set(theme_bw())
ggplot(data = sl, aes(x = Danger, y = TotalSleep)) + 
  geom_point(position = position_jitter(width = 0.05))
```

---

## Визуализация материала 

Точечный график --- не самый удобный способ представления таких данных. Лучше было бы изобразить средние значения и их 95% доверительные интервалы.


```{r gg-mean-conf-limit-coloured-labs, echo=FALSE, purl=FALSE}
ggplot(data = sl, aes(x = Danger, y = TotalSleep, colour = Danger)) + 
  stat_summary(geom = 'pointrange', fun.data = mean_cl_normal) +
  labs(x = 'Уровень опасности', 
       y = 'Продолжительность сна',
       colour = 'Уровень опасности')
```


---

class: middle, center, inverse

# Множественные сравнения

---

## Множественные сравнения: <br> число возможных сравнений

Мы могли бы сравнить среднюю продолжительность сна в разных группах при помощи t-критерия. У нас всего 5 групп. Сколько возможно между ними попарных сравнений?

```{r gg-mean-conf-limit-coloured-labs, echo=FALSE, purl=FALSE}
```

--

Всего возможно 10 сравнений.

---

## Множественные сравнения: <br> вероятность совершить ошибку I рода

Всего возможно 10 сравнений. Если для каждого вероятность ошибки I рода будет $\alpha_{per\ comparison} = 0.05$, то для всей группы из 10 сравнений --- ?

```{r gg-mean-conf-limit-coloured-labs, echo=FALSE, purl=FALSE}
```

--

Для независимых тестов вероятность совершить хотя бы одну ошибку I рода в группе сравнений будет $\alpha_{family\ wise} = 1 - (1 - 0.05)^{10} = `r 1 - (1 - 0.05)^{10}`$ (т.е. 40%).



<!-- зависимость между тестами снижает степень раздутия альфы (Winer et al. 1991), поэтому даже если тесты зависимы, можно действовать как для независимых тестов. -->
<!-- Winer, B. J., Brown, D. R., & Michels, K. M. (1991). Statistical principles in experimental design, 3rd ed. New York, NY: McGraw-Hill. -->

---

## Поправка Бонферрони

Если все-таки приходится делать много сравнений, нужно снизить $\alpha _{per\ comparison}$ до обычного уровня. Для этого фиксируем уровень $\alpha _{family\ wise}$ --- уровень значимости для одного сравнения. 

$$\alpha _{per\ comparison} = \frac{\alpha _{family\ wise}}{n}$$

--

Например, если хотим зафиксировать $\alpha _{family\ wise} = 0.05$.

С поправкой Бонферрони $\alpha _{per\ comparison} = 0.05 / 10 = 0.005$.

Это очень жесткая поправка! Мы рискуем не найти значимых различий, даже там, где они есть (ошибка II рода)...

Дисперсионный анализ позволит избежать такого рода поправок, поскольку будем тестировать гипотезу о том, что хотя бы _одно_ среднее значение значимо отлично от других средних. 

---

class: middle, center, inverse

# Дисперсионный анализ

```{r purl=FALSE, echo = FALSE, warning=FALSE}
library(dplyr)
dat_smr <- sl %>% group_by(Danger) %>% summarise(mean = mean(TotalSleep)) 
dat <- merge(sl, dat_smr)
dat$Danger <- as.numeric(dat$Danger) + runif(nrow(dat), -0.15, 0.15)
d_lev <- c('очень низкий', 'низкий', 'средний', 'высокий', 'очень высокий')
dat_smr$Danger <- as.numeric(dat_smr$Danger)

lims <- range(sl$TotalSleep) + c(-1, 1)
yannot <- lims[1] + 0.5
set.seed(832)
gmean <- mean(sl$TotalSleep, na.rm = TRUE)

# 31 33 43 46
id <- 43
Y <- dat$TotalSleep[id]
Y_hat <-dat$mean[id]
X <- dat$Danger[id]



pl <- ggplot(data = dat, aes(x = Danger, y = TotalSleep)) + theme(legend.position = 'none', axis.text.x = element_text(angle = 30, vjust = .8, hjust = .8)) + ylim(lims[1], lims[2]) + scale_x_continuous(breaks = 1:5, labels = d_lev)

# # Общая изменчивость (отклонения от общего среднего)
pl_tot <- pl + 
  geom_segment(aes(xend = Danger, yend = gmean), colour = 'grey70') +
    geom_hline(yintercept = gmean, linetype = 'dashed') + 
    geom_point() +
  ggtitle('Общая изменчивость\n(отклонения от общего среднего)') +
    annotate('text', label = 'Общее\nсреднее', 
           x = 0,  y = gmean, hjust = -0.1, size = 4) + 
  annotate('text', label = 'SS[t] == sum((y[i] - bar(y)))^2', parse = TRUE, x = 0,  y = yannot, hjust = -0.1, size = 6) 

pl_all <- pl + 
  geom_segment(aes(xend = Danger, yend = gmean), colour = 'grey70') +
  geom_point(data = dat_smr, aes(y = mean), size = 20, shape = 45, colour = 'dodgerblue1') + 
  geom_hline(yintercept = gmean, linetype = 'dashed') + 
  # annotate('segment', x = X, y = Y, xend = X, yend = gmean, colour = 'grey70', size = 2) + 
  annotate('segment', x = X, y = Y, xend = X, yend = Y_hat, colour = '#009E73', size = 2) +
  annotate('segment', x = X, y = Y_hat, xend = X, yend = gmean, colour = '#E69F00', size = 2) +
  geom_point() +
  annotate('text', label = 'Общее\nсреднее', 
           x = 0,  y = gmean, hjust = -0.1, size = 4)

pl_no <- pl + 
  geom_hline(yintercept = gmean, linetype = 'dashed') + 
  geom_point(data = dat_smr, y = gmean, size = 20, shape = 45, colour = 'dodgerblue1') +
    annotate('segment', x = X, y = Y, xend = X, yend = gmean, colour = 'grey70', size = 2) + 
  annotate('segment', x = X + 0.05, y = Y, xend = X + 0.05, yend = gmean, colour = '#009E73', size = 2) +
    geom_point() +
  annotate('text', label = 'Общее\nсреднее', 
           x = 0,  y = gmean, hjust = -0.1, size = 4)


# library(plyr)
# Межгрупповая изменчивость (связанная с фактором)
pl_x <- pl + 
  geom_hline(aes(yintercept = gmean), linetype = 'dashed') + 
  geom_segment(data = dat_smr, aes(x = Danger, y = mean, xend = Danger, yend = gmean), colour = '#E69F00', size = 2) +
  geom_point(data = dat_smr, aes(y = mean), size = 20, shape = 45, colour = 'dodgerblue1') + 
    geom_point() +
  ggtitle('Факторная изменчивость\n(межгрупповая)')+
    annotate('text', label = 'SS[x] == sum((hat(y)[i] - bar(y)))^2', parse = TRUE, x = 0,  y = yannot, hjust = -0.1, size = 6)

# Внутригрупповая изменчивость (случайная)
pl_res <- pl + 
  geom_segment(data = dat, aes(xend = Danger, yend = mean), colour = '#009E73') +
    geom_hline(yintercept = gmean, linetype = 'dashed') + 
    geom_point(data = dat_smr, aes(y = mean), size = 20, shape = 45, colour = 'dodgerblue1') + 
    geom_point() +
  ggtitle('Случайная изменчивость\n(внутригрупповая)')+
    annotate('text', label = 'SS[e] == sum(sum((y [i] - hat(y)[i])))^2', parse = TRUE, x = 0,  y = yannot, hjust = -0.1, size = 6)
```

---

## Дисперсионный анализ (Analysis Of Variance, ANOVA)

.pull-left[


```{r, echo=FALSE, fig.cap="Рональд Фишер"}
include_graphics("images/fisher.jpg")
```

]

.pull-right[

Он используется для сравнения средних значений зависимой переменной в дискретных группах, заданных факторами.

]

---

## Общая изменчивость

Общая изменчивость $SS_t$ --- это сумма квадратов отклонений наблюдаемых значений $y_i$ от общего среднего $\bar y$. 

```{r gg-tot, echo=FALSE, fig.height=3.5, purl=FALSE}
pl_tot
```

---

## Отклонения от общего среднего

.pull-left[
**Межгрупповые отклонения** --- отклонения внутригрупповых средних от общего среднего ("эффекты" групп) --- факторная изменчивость. 
```{r gg-between, echo=FALSE, purl=FALSE}
pl + 
  geom_hline(aes(yintercept = gmean), linetype = 'dashed') + 
  geom_segment(data = dat_smr, aes(x = Danger, y = mean, xend = Danger, yend = gmean), colour = '#E69F00', size = 2) +
  geom_point(data = dat_smr, aes(y = mean), size = 20, shape = 45, colour = 'dodgerblue1') + 
    geom_point() +
    annotate('text', label = 'SS[x] == sum((hat(y)[i] - bar(y)))^2', parse = TRUE, x = 0,  y = yannot, hjust = -0.1, size = 6)
```
]

.pull-right[
**Внутригрупповые отклонения** --- отклонения наблюдаемых значений от внутригрупповых средних --- случайная изменчивость.
```{r gg-inner, echo=FALSE, purl=FALSE}
pl + 
  geom_segment(data = dat, aes(xend = Danger, yend = mean), colour = '#009E73') +
    geom_hline(yintercept = gmean, linetype = 'dashed') + 
    geom_point(data = dat_smr, aes(y = mean), size = 20, shape = 45, colour = 'dodgerblue1') + 
    geom_point() +
    annotate('text', label = 'SS[e] == sum(sum((y [i] - hat(y)[i])))^2', parse = TRUE, x = 0,  y = yannot, hjust = -0.1, size = 6)
```

]

---

## Структура общей изменчивости

Общая изменчивость $SS_t$ складывается из изменчивости связанной с фактором $SS_x$ и случайной изменчивости $SS_e$.

$$SS_t = SS_x + SS_e$$

```{r gg-ss, echo=FALSE, fig.height=3.5, fig.width=10, purl=FALSE}
library(gridExtra)
grid.arrange(pl_tot, pl_x, pl_res, nrow = 1)
```

---

## Средние квадраты отклонений

.pull-left[.center[
$SS_t = SS_r + SS_e$
]
]

.pull-right[
.center[
$MS_t \ne MS_r + MS_e$
]
]

```{r gg-ss, echo=FALSE, purl=FALSE}
```

.small[
.pull-left-33[
Общая  
изменчивость  
$SS_{t}= \sum{(y_i - \bar{y})^2}$  

$df_{t} = n - 1$  

Общая дисперсия  
$MS_{t} = \frac {SS_{t}}{df_{t}}$
]

.pull-right-66[

.pull-left[
Факторная изменчивость  
$SS_{x}=\sum{(\hat{y}-\bar{y})^2}$  

$df_{x} = a - 1$  

Факторная дисперсия
$MS_{x} = \frac {SS_{x}}{df_{x}}$
]

.pull-right[
Остаточная изменчивость  
$SS_{e}= \sum{(y_i - \hat{y})^2}$  

$df_{e} = n - a$

Остаточная дисперсия  
$MS_{e} = \frac{SS_{e}}{df_{e}}$]
]
]

- $a$ — количество уровней фактора

---

##  Если выборки из одной совокупности, то  

Если выборки из одной совокупности, то наблюдения из разных групп будут отличаться друг от друга не больше, чем наблюдения из одной группы,  
т.е. факторная дисперсия будет близка к случайной дисперсии $MS_x \sim MS_e$. Их равенство можно проверить при помощи F-критерия

$$F_{df_x, df_e} = \frac{MS _{x}}{MS_{e}}$$


```{r gg-ss, echo=FALSE, fig.height=5, fig.width=12, purl=FALSE}
```

---

## F-критерий

.center[
$F_{df_x, df_e} = \frac{MS _{x}}{MS_{e}}$
]

Гипотезы: 

$H _0$: все выборки взяты из одной совокупности --- $\mu_1 = \mu_2  = \dots = \mu_a$. Тогда $MS _x = MS _e$

$H _A$: какая-то из выборок из другой совокупности, т.е. какое-то (даже одно) среднее значение $\mu_k$ отличается от других. Тогда $MS _x > MS _e$.

F-статистика подчиняется F-распределению. Форма F-распределения зависит от двух параметров: $df_{x} = a - 1$ и $df_{e} = n - a$.

```{r f-distribution, echo=FALSE, purl=FALSE, fig.width=7, fig.height=2}
dfr <- data.frame(f = seq(-0.01, 9, 0.01))
ggplot(dfr, aes(x = f)) + 
  stat_function(fun = df, args = list(df1 = 4, df2 = 53), size = 1.3, n = 200) + 
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = qf(p = 0.95, df1 = 4, df2 = 53), color = 'red', linetype = 'dashed') + 
  annotate('text', label = 'F при α = 0.05', x = qf(p = 0.95, df1 = 4, df2 = 53), y = 1, hjust = 1.1, vjust = 1) +
  geom_vline(xintercept = 8.0523, linetype = 'dashed') +
  annotate('text', label = 'F', x = 8.0523, y = 1, hjust = -1, vjust = 1) +
  labs(title = 'F-распределение, df1 = 4, df2 = 53', x = 'F', y = 'Плотность вероятности') + theme_bw(base_size = 10)
```

---

## Таблица дисперсионного анализа 

| Источник <br/> изменчивости  | SS | df | MS | F  |
| ---------------------------- | -- | -- | -- | --- |
| Название фактора | $SS _x = \sum{(\hat y_i - \bar y)^2}$ | $df _x = a - 1$ | $MS _x = \frac{SS _x}{df _x}$ | $F _{df _x df _e} = \frac{MS _x}{MS _e}$ |
| Случайная | $SS _e = \sum{(y _i - \hat y _i)^2}$ | $df _e = n - a$ | $MS _e = \frac{SS _e}{df _e}$ |
| Общая | $SS _t = \sum {(y _i - \bar y)^2}$ | $df _t = n - 1$ | | |



.Large[
Минимальное упоминание результатов в тексте должно содержать $F _{df _x, df _e}$ и $p$.
]

---

class: middle, center, inverse

## Дисперсионный анализ в R

---

## Дисперсионный анализ в R


```{r}
sl_anova <- aov(TotalSleep ~ Danger, data = sl)
summary(sl_anova)
```


---

## Описание результатов дисперсионного анализа

Результаты дисперсионного анализа можно представить в виде таблицы

- Общая продолжительность сна различается у видов животных, которые в разной степени подвержены опасностям в течение жизни.

| | SS | df | F | P |
| -- | -- | -- | - | - | 
| Уровень опасности | 457.3 | 4 | 8.1 | <0.01 | 
|  Остаточная | 752.4 | 53 |  |  |

---


### Условия примененимости дисперсионного анализа:

- Случайность и независимость групп и наблюдений внутри групп
- Нормальное распределение 
- Гомогенность дисперсий 

--

### Другие ограничения

- Лучше работает, если размеры групп примерно одинаковы (т.н. сбалансированный дисперсионный комплекс)
- Устойчив к отклонениям от нормального распределения (при равных объемах групп или при больших выборках)

---

## Анализ остатков

Остатки - это исходные данные из которых удален эффект, который интересует исследователя. В нашем случае - это средние значения в пределах каждой группы.


$$
Residual = y_{i,j} - \hat{y_j} 
$$


```{r purl=FALSE}
# Данные для анализа остатков
sl_diag <- fortify(sl_anova)
```

---

## График рассеяния остатков

```{r purl=FALSE}
# График остатков от предсказанных значений
ggplot(data = sl_diag, aes(x = .fitted, y = .resid)) + 
  geom_point()
```

--

- Есть признаки **гетероскедастичности** - в одной из групп маленький разброс.

В данном случае это не страшно, т.к. однофакторный дисперсионный анализ устойчив к ситуации, когда в одной из групп разброс меньше, чем в других (особенно, если данные не слишком несбалансированные) (Underwood, 1997, McGuinness, 2002).

---

# Диагностика с помощью боксплотов: 

Если предиктор --- дискретная переменная, то вместо обычного точечного графика остатков лучше построить боксплот остатков.

```{r purl=FALSE}
# График остатков от значений дискретного предиктора
ggplot(data = sl_diag, aes(x = Danger, y = .resid)) + geom_boxplot() + geom_hline(yintercept = 0)
```

--

- Остатки в пределах двух стандартных отклонений.
- Подозрительно маленькая дисперсия продолжительности сна в группе с очень высоким уровнем опасности.

---

## Решение: 

```{r purl=FALSE, fig.height=6, fig.width=8}
library(car)
qqPlot(sl_diag$.resid)
```

--

- Остатки распределены нормально


---

class: middle, center, inverse

# Post hoc тесты

---

## Post hoc тесты

Дисперсионный анализ показывает, есть ли влияние фактора (т.е. различаются ли средние значения зависимой переменной между группами)

Пост-хок тесты показывают, какие именно из возможных пар средних значений различаются.

---

## Какие бывают post hoc тесты

Тесты без поправки на число сравнений:

- Наименьшая значимая разница Фишера (Fisher's Least Significant Difference)

Тесты с поправкой для уровня значимости $\alpha$:

- Поправка Бонферрони (Bonferroni correction)
- Поправка Сидака (Šidák's correction)

Тесты, основанные на распределении стьюдентизированного размаха:

- **Тест Тьюки** (Tukey's Honest Significant Difference, HSD)
- Тест Стьюдента-Ньюмена-Кьюлса (Student-Newman-Kewls test, SNK)
- Тест Даннета (Dunnet's test) --- используется для сравнения с контрольной группой

Тесты, основанные на F-тестах:

- Критерий Дункана (Dunkan's test)
- Тест Шеффе (Scheffe's test)

---

## Свойства post hoc тестов для попарных сравнений средних

- Применяются, если только **влияние фактора значимо**
- Делают поправку для снижения вероятности ошибки I рода $\alpha$ (но не слишком, чтобы не снизилась мощность, и не увеличилась вероятность ошибки второго рода $\beta$)
  - Учитывают величину различий между средними
  - Учитывают количество сравниваемых пар
- Различаются по степени консервативности (тест Тьюки --- разумный компромисс) 
- Работают лучше при равных объемах групп, при гомогенности дисперсий

---

## Тест Тьюки (Tukey's Honest Significant Difference)

Используется стьюдентизированный t-критерий  
с $df = df_e = n - p$ и $m = p$ (общее число групп):

$$q = \frac{\bar{y}_i - \bar{y}_j}{\sqrt{MS_e\frac{1}{2} \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$

Требуется равенство дисперсий.

---

## Пост хок тест Тьюки в R

```{r, warning=FALSE, message=FALSE}

sl_Tuk <- TukeyHSD(sl_anova)

```

---

## Результаты попарных сравнений (тест Тьюки)

```{r, R.options=list(width = 80)}
sl_Tuk
```

---

## Описываем результаты пост хок теста

- Продолжительность сна у видов, подвергающихся очень высокому уровню опасности в течение жизни, значительно меньше, чем у тех, кто живет при среднем, низком и очень низком уровне опасности (тест Тьюки, $p < 0.05$). 

--

Но лучше еще и нарисовать график и обозначить различающиеся средние.

---

```{r, echo=FALSE}
Pl_sl <- 
sl %>% 
  group_by(Danger) %>% 
  summarise(Mean = mean(TotalSleep),
            Sd = sd(TotalSleep),
            n = n(),
            SE = Sd/sqrt(n),
            CI_low = Mean - qt(p = 0.975, df = n - 1) * SE,
            CI_up = Mean + qt(p = 0.975, df = n - 1) * SE) %>% 
  ggplot(., aes(x = Danger, y = Mean)) +
  geom_col(fill = "gray") +
  geom_errorbar(aes(ymin = CI_low, ymax = CI_up), width = 0.2)
  
Pl_sl +
  geom_segment(aes(y = 16.6, yend = 16.6, x = "очень высокий", xend = "очень низкий")) +
  geom_segment(aes(y = 16.4, yend = 16.4, x = "очень высокий", xend = "низкий")) +
   geom_segment(aes(y = 16.2, yend = 16.2, x = "очень высокий", xend = "средний"))
```




---



## Take home messages

- При множественных попарных сравнениях увеличивается вероятность ошибки первого рода. Поправка Бонферрони --- способ точно рассчитать, насколько нужно снизить уровень значимости для каждого из сравнений
- При помощи дисперсионного анализа можно проверить гипотезу о равенстве средних значений
- Условия применимости (должны выполняться, чтобы тестировать гипотезы)
    - Случайность и независимость групп и наблюдений внутри групп
    - Нормальное распределение
    - Гомогенность дисперсий
- Post hoc тесты --- это попарные сравнения после дисперсионного анализа, которые позволяют сказать, какие именно средние различаются

---

## Дополнительные ресурсы

- Quinn, Keough, 2002, pp. 173-207
- Logan, 2010, pp. 254 - 282
- [Open Intro to Statistics](http://www.openintro.org/stat/) 
- Sokal, Rohlf, 1995, pp. 179-260
- Zar, 2010, pp. 189-207
