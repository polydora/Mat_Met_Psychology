---
title: "Множественная регрессия"
author: Марина Варфоломеева, Вадим Хайтов
output:
  ioslides_presentation:
    widescreen: true
    css: assets/my_styles.css
    logo: assets/Linmod_logo.png
  beamer_presentation:
    colortheme: beaver
    highlight: tango
    includes:
      in_header: ./includes/header.tex
    pandoc_args:
    - --latex-engine=xelatex
    - -V fontsize=10pt
    - -V lang=russian
    slide_level: 2
    theme: default
    toc: no
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6, digits = 3)
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE)
```

## Множественная регрессия



### Вы сможете

+ Подобрать модель множественной линейной регрессии
+ Протестировать ее статистическую значимость и валидность

## Пример: птицы в лесах Австралии

Фрагментация лесных местообитаний - одна из важнейших проблем Австралии.
От каких характеристик лесного участка зависит обилие птиц во фрагментированных лесных массивах? (Loyn, 1987)

<div class="columns-2">

![forest in Victoria, Australia](images/vict_m.jpg)
<small>Mystic Forest - Warburton, Victoria by ¡kuba! on flickr</small>

56 лесных участков:

- ABUND - обилие птиц
- AREA - площадь участка
- YRISOL - год изоляции участка
- DIST - расстояние до ближайшего леса
- LDIST - расстояние до ближайшего большого леса
- GRAZE - пастбищная нагрузка (1-5)
- ALT - высота над уровнем моря

</div>

<small>Пример из кн. Quinn, Keugh, 2002, данные из Loyn, 1987)</small>

## Читаем данные

```{r}
bird <- read.table("data/loyn.csv", sep = ",", header = TRUE)
```
Все ли правильно открылось?

```{r}
str(bird)
```

Есть ли пропущенные значения?

```{r}
colSums(is.na(bird))
```



## Можно ли ответить на вопрос таким методом?

```{r}
cor(bird)
```

>- Нет

>- Обычная корреляция не учитывает, что взаимосвязь между переменными может находиться под контролем других переменных и их взаимодействий.
>- Множественные тесты. При тестировании значимости множества коэффициентов корреляции нужно вводить поправку для уровня значимости. Лучше было бы учесть все в одном анализе.

## Нам предстоит построить модель множественной линейной регрессии

$$y_i = b_0 + b_1x_{1i} + b_2x_{2i} + b_3x_{3i} + ... + b_{p - 1}x_{p - 1\;i} + e_i$$

- $y_i$ --- значение зависимой переменной для $i$-того наблюдения
- $b_0$ --- свободный член (intercept). Значение $y$ при $x_1 = x_2 = x_3= \ldots = x_{p - 1} = 0$
- $b_1$ --- частный угловой коэффициент для зависимости $y$ от $x_1$. Показывает, на сколько единиц изменяется $y$ при изменении $x_1$ на одну единицу и при условии, что все остальные предикторы не изменяются
$b_2$, $b_3$, ...., $b_{p - 1}$ --- аналогично
- $e_i$ --- варьирование $y$, не объясненное данной моделью
- $p$ --- число параметров модели


## Геометрическая интерпретация множественной линейной модели 

### Для случая с одним предиктором $y_i = b_0 + b_1x_{1i} + e_i$ --- линия регрессии

```{r, echo=FALSE, purl=FALSE}
library(ggplot2)
dfr <- data.frame(x1 = runif(25, 0, 10))
dfr$y1 <- 5 + 5 * dfr$x1 + rnorm(25, 0, 5)
ggplot(data = dfr, aes(x = x1, y = y1)) + geom_point() + geom_smooth(method = "lm") + ylab("y")
```

## Геометрическая интерпретация множественной линейной модели

### Для случая с двумя предикторами $y_i = b_0 + b_1x_{1i} + b_2x_{2i} + e_i$ --- плоскость в трехмерном пространстве

```{r, echo=FALSE, fig.height=5, fig.width=5, purl=FALSE}
library(plot3D)

dfr$x2 <- runif(25, 10, 20)
dfr$y2 <- 5 + 5 * dfr$x1 + 3 * dfr$x2 + rnorm(25, 0, 15)
fit <- lm(y2 ~ x1 + x2, data = dfr)

# predict values on regular xy grid
x1.pred <- seq(0, 10, length.out = 20)
x2.pred <- seq(10, 20, length.out = 20)
xy <- expand.grid(x1 = x1.pred, 
                  x2 = x2.pred)

y2.pred <- matrix(nrow = 20, ncol = 20, 
                  data = predict(fit, newdata = xy, 
                                 interval = "prediction"))

# fitted points for droplines to surface
fitpoints <- predict(fit) 

scatter3D(x = dfr$x1, y = dfr$x2, z = dfr$y2, 
          pch = 18, cex = 1.5,
          theta = 50, phi = 36,
          ticktype = "detailed",
          surf = list(x = x1.pred, y = x2.pred, z = y2.pred,
                      facets = NA, fit = fitpoints),
          xlab = "First predictor X1", ylab = "Second predictor X2",
          zlab = "Response variable",
          main = "")
```

## Геометрическая интерпретация множественной линейной модели

### Для случая с большим количеством предикторов 

$$y_i = b_0 + b_1x_{1i} + b_2x_{2i} + b_3x_{3i} + ... + b_{p - 1}x_{p - 1\;i} + e_i$$

Плоскость в n-мерном пространстве, оси которого образованы значениями предикторов



# Разведочный анализ данных 


## Знакомство с данными {.smaller}

```{r fig.height=5, fig.width=10}
library(car)
pairs(bird)
```

## Итог предварительного знакомства с данными

- Большая часть значений  AREA, DIST, LDISТ сгруппирована в начале области определения. Связь между AREA и откликом выглядит нелинейной. Нужно логарифмировать эти переменные.

- Переменная GRAZE --- это уровень выпаса скота __в баллах__, ее лучше было бы анализировать как дискретную переменную. Технически, ее можно анализировать и как непрерывную, но нужно помнить, это предполагает одинаковые различия между разными соседними уровнями выпаса скота. Это нереалистично.


Трансформируем переменные

```{r}
bird$logAREA <- log(bird$AREA)
bird$logDIST <- log(bird$DIST)
bird$logLDIST <- log(bird$LDIST)
```

## Ищем отскоки

__Отскоки (выбросы, outliers)__ - наблюдения, которые имеют более высокие (или низкие) значения относительно большинства других наблюдений.

## Ищем отскоки: точечные диаграммы Кливленда {.columns-2 .smaller}


```{r fig.width=6}
ggplot(bird, aes(y = 1:nrow(bird), x = ABUND)) + 
  geom_point() + 
  labs(y = 'Порядковый номер \nв датасете', x = 'Значения переменной')
```


## Ищем отскоки: точечные диаграммы Кливленда {.columns-2 .smaller}


```{r fig.width=4}
ggplot(bird, aes(y = 1:nrow(bird), x = AREA)) + 
  geom_point() + 
  labs(y = 'Порядковый номер \nв датасете', 
       x = 'Значения переменной')
```



```{r fig.width=4}
ggplot(bird, aes(y = 1:nrow(bird), x = logAREA)) + 
  geom_point() + 
  labs(y = 'Порядковый номер \nв датасете', 
       x = 'Значения переменной')
```



## Ищем отскоки: диаграммы Кливленда для всех переменных


```{r gg-arrange, echo=FALSE, fig.height=5}
gg_dot <- ggplot(bird, aes(y = 1:nrow(bird))) + geom_point() + ylab('index')
Pl1 <- gg_dot + aes(x = ABUND)
Pl2 <- gg_dot + aes(x = YRISOL)
Pl3 <- gg_dot + aes(x = logAREA)
Pl4 <- gg_dot + aes(x = logDIST)
Pl5 <- gg_dot + aes(x = logLDIST)
Pl6 <- gg_dot + aes(x = ALT)
Pl7 <- gg_dot + aes(x = GRAZE)

library(cowplot) # пакет для группировки графиков
theme_set(theme_bw())
plot_grid(Pl1, Pl2, Pl3, Pl4, Pl5, Pl6, 
          Pl7, ncol = 3, nrow = 3)
```


## Ищем отскоки: диаграммы Кливленда для всех переменных

Код для  графика

```{r gg-arrange, echo=TRUE, eval=FALSE, purl=TRUE}
```



## Проблемы: сильные корреляции между некоторыми предикторами

```{r fig.height=6, fig.width=10, echo=FALSE}
pairs(bird[, c("ABUND", "logAREA", "YRISOL", "logDIST", "logLDIST", "GRAZE", "ALT")])
```


## Модель, которую мы хотим подобрать

$$\begin{aligned}{ABUND}_i &= b_0 + b_1 \cdot logAREA_i + b_2 \cdot YRISOL_i + \\
&+ b_3 \cdot logDIST_i + b_4 \cdot logLDIST_i + b_5 \cdot GRAZE_i + b_6 \cdot ALT_i + e_i\\
\end{aligned}$$

Возможно, что эту модель придется изменить.

В начале нам нужно убедиться, что условия применимости линейной регрессии выполняются.

## Вспомним условия применимости линейной регрессии

- Линейная связь между зависимой переменной ($Y$) и предикторами ($X$)
- Независимость значений $Y$ друг от друга
- Нормальное распределение $Y$ для каждого уровня значений $X$
- Гомогенность дисперсий $Y$ для каждого уровня значений $X$
- __Отсутствие коллинеарности предикторов (для можественной регрессии)__

# Мультиколлинеарность

## Мультиколлинеарность

Мультиколлинеарность ---  наличие линейной зависимости между независимыми переменными (предикторами) в регрессионной модели.

При наличии мультиколлинеарности оценки параметров неточны, а значит сложно интерпретировать влияние предикторов на отклик.

### Косвенные признаки мультиколлинеарности:

- Большие ошибки оценок параметров     
- Большинство значений параметров модели незначимо отличается от нуля, но F критерий говорит, что модель в целом значима.

### Проверка на мультиколлинеарность

- Коэффициент раздутия дисперсии (Variance inflation factor, VIF).

## Как рассчитывается VIF

Пусть наша модель $y_i = b_0 + b_1 x_{1i} + b_2 x_{2i} + \ldots + b_{p - 1} x_{p - 1\;i} + e_i$.

Нужно оценить какую долю изменчивости конкретного предиктора могут объяснить другие предикторы (т.е. насколько предикторы независимы).

Для каждого предиктора:

1. Строим регрессионную модель данного предиктора от всех остальных:
$$x_1 = c_0 + c_1x_2 +c_2x_3 + .... + c_{p - 2}x_{p - 1}$$
2. Находим $R^2$ этой модели.
3. Вычисляем коэффициент раздутия дисперсии:
$$VIF = \frac{1}{1-R^2}$$

## Мультиколлинеарность опасна

В случае наличия мультиколлинеарности:

- Оценки коэффициентов модели нестабильны (даже могут менять знак при небольших
изменениях модели или исходных данных).
- Стандартные ошибки оценок параметров увеличатся в $\sqrt{VIF}$ раз.
- В результате меньше шансов заметить влияние предиктора, т.к. уровень значимости (p-value) в тестах будет выше.


## Как бороться с мультиколлинеарностью?

- Можно последовательно удалить из модели избыточные предикторы с VIF > 2  
    1. подбираем модель
    2. считаем VIF
    3. удаляем предиктор с самым большим VIF
    4. повторяем 1-3

- Можно заменить исходные предикторы новыми независимыми друг от друга переменными, сконструированными методом главных компонент (Principal component analysis, PCA).

## Задание

- Постройте множественную линейную регрессию для зависимости обилия птиц (`ABUND`) от других переменных (`logAREA`, `YRISOL`, `logDIST`, `logLDIST`, `GRAZE`, `ALT`)

$$\begin{aligned}{ABUND}_i &= b_0 + b_1 \cdot logAREA_i + b_2 \cdot YRISOL_i + \\
&+ b_3 \cdot logDIST_i + b_4 \cdot logLDIST_i + b_5 \cdot GRAZE_i + b_6 \cdot ALT_i + e_i\\
\end{aligned}$$

- Используйте функцию `vif()`, чтобы проверить, коллинеарны ли предикторы.

Дополните код:

```{r eval=FALSE, purl=TRUE}
mod1 <- lm(formula = , data = )
vif()
```

## Решение

```{r}
# Строим модель
mod1 <- lm(formula = ABUND ~  logAREA + YRISOL + logDIST + logLDIST + GRAZE + ALT, 
           data = bird)
# Проверяем, есть ли коллинеарность?
vif(mod1)
```

В нашей модели сильной мультиколлинеарности нет.

Однако, возможно `GRAZE` --- избыточный предиктор.

## Удалим из модели избыточный предиктор

```{r}
mod2 <- update(mod1, . ~ . -GRAZE)
vif(mod2)
```

Теперь мультиколлинеарности нет. В модели осталось пять предикторов (и шесть параметров).


$$\begin{aligned}{ABUND}_i &= b_0 + b_1 \cdot logAREA_i + b_2 \cdot YRISOL_i + \\
&+ b_3 \cdot logDIST_i + b_4 \cdot logLDIST_i + b_5 \cdot ALT_i + e_i\\
\end{aligned}$$

## Уравнение модели

$$\begin{aligned}{ABUND}_i &= b_0 + b_1 \cdot logAREA_i + b_2 \cdot YRISOL_i + \\
&+ b_3 \cdot logDIST_i + b_4 \cdot logLDIST_i + b_5 \cdot ALT_i + e_i\\
\end{aligned}$$

Мы подобрали коэффициенты и можем записать уравнение модели.

```{r}
coef(mod2)
```

$$\begin{aligned}{ABUND}_i &= -226.00 + 3.69 \cdot logAREA_i + 0.12 \cdot YRISOL_i - \\
&-0.10 \cdot logDIST_i -0.33 \cdot logLDIST_i + 0.03 \cdot ALT_i + e_i\\
\end{aligned}$$



## Задание

Проверьте, выполняются ли условия применимости для модели `mod2`. Дополните код:

```{r eval=FALSE, purl=TRUE}
library()
mod2_diag <- data.frame(fortify(), $GRAZE)
# 1) График расстояния Кука
ggplot(data = , aes(x = 1:, y = .cooksd)) + geom_bar(stat = "")
# 2) График остатков от предсказанных значений
gg_resid <- ggplot(data = , aes(x = , y = )) + geom_point() + geom_hline()
gg_resid
# 3) Графики остатков от предикторов в модели и нет
res_1 <- gg_resid + aes(x = logAREA)
res_1
res_2 <- gg_resid
res_3 <- gg_resid
res_4 <- gg_resid
res_5 <- gg_resid
res_6 <- gg_resid
# все графики вместе
library(gridExtra)
grid.arrange(res_1, res_2, nrow = 2)
# 4) Квантильный график остатков
library(car)
qq
```

## Решение

### График остатков от предсказанных значений

- Выбросов нет
- Гетерогенность дисперсии?
- Два наблюдения с очень большими предсказанными значениями и большими остатками. Хорошо бы проверить их.

```{r solution-1a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=2.2}

mod2_diag <-  fortify(mod2)
  
gg_resid <- ggplot(data = mod2_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + geom_hline(yintercept = 0)
gg_resid
```


## Решение

### Графики остатков от предикторов в модели и не вошедших в модель

- Величина остатков зависит от уровня выпаса скота. Возможно, не стоило удалять эту переменную
- Есть наблюдения с экстремальными значениями предикторов (два больших леса, один далекий, один высокогорный).  Хорошо бы проверить их.
```{r solution-2a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=5, echo=FALSE}
res_1 <- gg_resid + aes(x = logAREA)
res_2 <- gg_resid + aes(x = YRISOL)
res_3 <- gg_resid + aes(x = logDIST)
res_4 <- gg_resid + aes(x = logLDIST)
res_6 <- gg_resid + aes(x = ALT)

library(gridExtra)
grid.arrange(res_1, res_2, res_3, res_4,
              res_6, nrow = 2)
```

## Решение

###  Код для графиков остатков от предикторов в модели и нет

```{r solution-2a, fig.show='hide', purl=FALSE, echo=TRUE}
```

## Решение

### Квантильный график остатков

- Отклонения от нормального распределения остатков незначительны

```{r solution-3a, purl=FALSE, fig.width=4, fig.height=4, message=FALSE}
library(car)
qqPlot(mod2)
```

## Описание множественной линейной регрессии

- Записываем уравнение модели. 
- Общую значимость модели оцениваем при помощи _F_-критерия. 
- Качество подгонки модели описываем при помощи коэффициента детерминации с поправкой ($R^2_{adj.}$).
- При обсуждении значимости отдельных предикторов можно привести таблицу с оценками коэффициентов и тестами их значимости. 
- При сравнении влияния отдельных предикторов приводим стандартизованные коэффициенты
- Приводим график предсказаний модели


## Что почитать

+ Гланц, С., 1998. Медико-биологическая статистика. М., Практика
+ Кабаков Р.И. R в действии. Анализ и визуализация данных на языке R. М.: ДМК Пресс, 2014
+ Diez, D.M., Barr, C.D. and Çetinkaya-Rundel, M., 2015. OpenIntro Statistics. OpenIntro.
+ Zuur, A., Ieno, E.N. and Smith, G.M., 2007. Analyzing ecological data. Springer Science & Business Media.
+ Quinn G.P., Keough M.J. 2002. Experimental design and data analysis for biologists
+ Logan M. 2010. Biostatistical Design and Analysis Using R. A Practical Guide
